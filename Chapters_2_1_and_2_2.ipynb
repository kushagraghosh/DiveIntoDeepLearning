{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVxgTXtbDa79"
      },
      "source": [
        "# Dive into Deep Learning (DDL): Ch. 2.1,2.2\n",
        "Kushagra Ghosh, DDL: https://d2l.ai/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kAS0T4vQDfkD"
      },
      "outputs": [],
      "source": [
        "#Store data using n dimensional arrays called tensors\n",
        "#Similar to ndarray in NumPy but it leverages GPUs to accelerate numberic computation, and it supports automatic differentiation)\n",
        "\n",
        "#import PyTorch library\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w-q5uomsjr9",
        "outputId": "8000dd72-f106-4938-8c99-fe0c2ec00e92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n",
            "12\n",
            "torch.Size([12])\n"
          ]
        }
      ],
      "source": [
        "#1d tensor is vector, 2 axes called a matrix, more is called kth order tensor\n",
        "\n",
        "#arange(n) used to create a vector of evenly spaced values (12 elements), starting at 0 (included) and ending at n (not included). Stored in main mem and designated for CPU-based computation.\n",
        "x = torch.arange(12, dtype=torch.float32)\n",
        "print(x)\n",
        "\n",
        "print(x.numel()) #num elements in the tensor\n",
        "print(x.shape) #tensorâ€™s shape (the length along each axis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkkaf5YmsoGA",
        "outputId": "5f107952-0f21-437c-d613-618a5d5fbc73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.],\n",
            "        [ 4.,  5.,  6.,  7.],\n",
            "        [ 8.,  9., 10., 11.]])\n"
          ]
        }
      ],
      "source": [
        "# reshape to change shape of tensor without changing vals. From (12,) -> (3,4)\n",
        "X = x.reshape(3, 4)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5mVrOoPssD6",
        "outputId": "0c917442-adf7-41c7-e220-91abc0f8bda3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]])\n",
            "tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[2, 1, 4, 3],\n",
              "        [1, 2, 3, 4],\n",
              "        [4, 3, 2, 1]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(torch.zeros((2, 3, 4))) #tensor with all zeroes\n",
        "print(torch.ones((2, 3, 4))) #tensor with all ones\n",
        "\n",
        "torch.randn(3, 4) #random elements drawn from Guassian (normal) distribution w/ mean 0 and stdev 1\n",
        "torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) #making tensor with exact vals for each element (outer list axis 0, inner list axis 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eukcEcdCsw-f",
        "outputId": "8d9e4645-9d8c-42e8-a070-c2c0fc5f12f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 8.,  9., 10., 11.]) tensor([[ 4.,  5.,  6.,  7.],\n",
            "        [ 8.,  9., 10., 11.]])\n",
            "tensor([[12., 12., 12., 12.],\n",
            "        [12., 12., 12., 12.],\n",
            "        [ 8.,  9., 10., 11.]])\n"
          ]
        }
      ],
      "source": [
        "print(X[-1], X[1:3]) #slicing\n",
        "X[1, 2] = 17 #writing\n",
        "X[:2, :] = 12 #assigning multiple elements the same val\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMv9WvmSrMcO",
        "outputId": "ccd9ccec-565c-49ab-f090-d5f86d6f8551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([162754.7969, 162754.7969, 162754.7969, 162754.7969, 162754.7969,\n",
            "        162754.7969, 162754.7969, 162754.7969,   2980.9580,   8103.0840,\n",
            "         22026.4648,  59874.1406])\n",
            "tensor([ 3.,  4.,  6., 10.]) tensor([-1.,  0.,  2.,  6.]) tensor([ 2.,  4.,  8., 16.]) tensor([0.5000, 1.0000, 2.0000, 4.0000]) tensor([ 1.,  4., 16., 64.])\n"
          ]
        }
      ],
      "source": [
        "#elementwise operation (scalar operation to each element of tensor, scalar -> scalar), unary (taking 1 input) and goes from real num to real num\n",
        "print(torch.exp(x)) #e^x\n",
        "\n",
        "#binary scalar operation, pair of real num -> single val nun, lifting scalar func to elementwise vector/tensor operation\n",
        "x = torch.tensor([1.0, 2, 4, 8])\n",
        "y = torch.tensor([2, 2, 2, 2])\n",
        "print(x + y, x - y, x * y, x / y, x ** y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNrjWrW2s4Uk",
        "outputId": "e51e6291-f3c3-4464-8b36-00304b9a281f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.],\n",
            "        [ 4.,  5.,  6.,  7.],\n",
            "        [ 8.,  9., 10., 11.],\n",
            "        [ 2.,  1.,  4.,  3.],\n",
            "        [ 1.,  2.,  3.,  4.],\n",
            "        [ 4.,  3.,  2.,  1.]])\n",
            "tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
            "        [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
            "        [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]])\n"
          ]
        }
      ],
      "source": [
        "#concatenate tensors (stacking them)\n",
        "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
        "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "\n",
        "print(torch.cat((X, Y), dim=0)) #stacking them along rows (axis 0, new axis 0 len is 3+3)\n",
        "print(torch.cat((X, Y), dim=1)) #stacking them along rows (axis 1, new axis 1 len is 4+4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD3ke7zBtNUW",
        "outputId": "823ece7f-5f59-4b90-e96d-29f40a2b7a68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[False,  True, False,  True],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#binary tensor with logical statements\n",
        "X == Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9snxwc2t7X0",
        "outputId": "10d255f1-2476-4cc7-a1f1-f054346f3696"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(66.)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#summing all elem of tensor gives tensor w/ 1 element\n",
        "X.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfvrFxuQuC6K",
        "outputId": "308f10a9-13d2-4160-b0f6-5f7cd0468e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0],\n",
            "        [1],\n",
            "        [2]]) tensor([[0, 1]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [1, 2],\n",
              "        [2, 3]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#broadcasting: expand array by copying element along axes w/ length 1 to make both tensors have same shape, then do elementwise operation\n",
        "a = torch.arange(3).reshape(3, 1)\n",
        "b = torch.arange(2).reshape(1, 2)\n",
        "print(a, b)\n",
        "a+b #replicating a along cols and b along rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ0cOVG90GG3",
        "outputId": "5a9328cd-83a2-4fe4-952e-28188c0fcca3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Python first evaluates Y + X, allocating new mem for result, then points Y to this new location in mem (dereferneces tensor that Y used to point to and point Y at new allocated mem)\n",
        "before = id(Y)\n",
        "Y = Y+X\n",
        "id(Y) == before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRULvvkW0ltU",
        "outputId": "825c1885-256a-4768-9776-a01f3542d849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id(Z): 140264904398704\n",
            "id(Z): 140264904398704\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#We want in-place updates since we may point at same parameters from multiple variables, and we want to update all of those references to avoid memory leak or refering to stale parameters\n",
        "\n",
        "Z = torch.zeros_like(Y)\n",
        "print('id(Z):', id(Z))\n",
        "Z[:] = X + Y #in-place operation\n",
        "print('id(Z):', id(Z))\n",
        "\n",
        "before = id(Y)\n",
        "Y += X #same as Y[:] = Y + X, in-place\n",
        "id(Y) == before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpFbEGar1mnV",
        "outputId": "fb3515d8-c181-4c0b-d1b0-d8b47a95454e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([3.5000]), 3.5, 3.5, 3)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = X.numpy() #Torch tensor -> NumPy array\n",
        "B = torch.from_numpy(A) #NumPy array -> Torch tensor\n",
        "type(A), type(B)\n",
        "\n",
        "a = torch.tensor([3.5])\n",
        "a, a.item(), float(a), int(a) #Size 1 tensor -> scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1_RMViz2U5q",
        "outputId": "fd3e105d-7f3e-4f8b-d25f-8bc812024487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   NumRooms RoofType   Price\n",
            "0       NaN      NaN  127500\n",
            "1       2.0      NaN  106000\n",
            "2       4.0    Slate  178100\n",
            "3       NaN      NaN  140000\n",
            "   NumRooms  RoofType_Slate  RoofType_nan\n",
            "0       3.0           False          True\n",
            "1       2.0           False          True\n",
            "2       4.0            True         False\n",
            "3       3.0           False          True\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[3., 0., 1.],\n",
              "         [2., 0., 1.],\n",
              "         [4., 1., 0.],\n",
              "         [3., 0., 1.]], dtype=torch.float64),\n",
              " tensor([127500., 106000., 178100., 140000.], dtype=torch.float64))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Reading CSV files and loading datasets into pandas\n",
        "\n",
        "import os\n",
        "\n",
        "os.makedirs(os.path.join('..', 'content', 'data'), exist_ok=True)\n",
        "data_file = os.path.join('..', 'content', 'data', 'house_tiny.csv')\n",
        "with open(data_file, 'w') as f:\n",
        "    f.write('''NumRooms,RoofType,Price\n",
        "NA,NA,127500\n",
        "2,NA,106000\n",
        "4,Slate,178100\n",
        "NA,NA,140000''')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(data_file)\n",
        "print(data)\n",
        "\n",
        "inputs, targets = data.iloc[:, 0:2], data.iloc[:, 2]\n",
        "inputs = pd.get_dummies(inputs, dummy_na=True) #Treating NaN and Slate as two differen categories of RoofType for 2 seperate columns\n",
        "inputs = inputs.fillna(inputs.mean()) #Replacing NaN values for NumRooms with mean of column\n",
        "print(inputs)\n",
        "\n",
        "X = torch.tensor(inputs.to_numpy(dtype=float))\n",
        "y = torch.tensor(targets.to_numpy(dtype=float))\n",
        "X, y #Load into tensor"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
